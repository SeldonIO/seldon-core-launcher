{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping a Model for Serving in Seldon\n",
    "\n",
    "Wrap a scikit-learn python model for use as a prediction microservice in seldon-core\n",
    "   \n",
    " * If you are viewing this on the web then to run this notebook install jupyter and follow the steps below and click on wrap_model.ipynb when the jupyter page is shown:\n",
    " ```\n",
    " git clone https://github.com/SeldonIO/seldon-core-launcher.git\n",
    " cd seldon-core-launcher/seldon-core/getting_started/wrap-model\n",
    " jupyter notebook\n",
    " ```\n",
    "\n",
    "## Requirements\n",
    "\n",
    "\n",
    " * You have a running cluster installed via the Google Marketplace with all the defaults including:\n",
    "    * NodePort for the Seldon API OAuth Gateway. This gateway is used to connect your business apps to your running models via REST and gRPC.\n",
    "    * The cluster is running in the default namespace\n",
    " \n",
    "## Dependencies\n",
    "\n",
    "You will need install the following dependencies:\n",
    "\n",
    " * [S2I](https://github.com/openshift/source-to-image)\n",
    " * [sklearn](http://scikit-learn.org/stable/) to train the model\n",
    " * [grpcio-tools](https://grpc.io/docs/quickstart/python.html) to allow testing using gRPC\n",
    " \n",
    "Sklearn and gRPC packages can easily be installed using pip:\n",
    "```bash\n",
    "pip install sklearn\n",
    "pip install grpcio-tools\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model\n",
    "We will train a model for the Iris classification task. In this simple dataset we try to classifier a type if Iris based on its petal and sepal length. \n",
    "<img src=\"./iris.jpg\" alt=\"iris\" title=\"iris\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iris data set...\n",
      "Dataset loaded!\n",
      "Training model...\n",
      "Model trained!\n",
      "Saving model in IrisClassifier.sav\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "\n",
    "def main():\n",
    "    clf = LogisticRegression()\n",
    "    p = Pipeline([('clf', clf)])\n",
    "    print('Training model...')\n",
    "    p.fit(X, y)\n",
    "    print('Model trained!')\n",
    "\n",
    "    filename_p = 'IrisClassifier.sav'\n",
    "    print('Saving model in %s' % filename_p)\n",
    "    joblib.dump(p, filename_p)\n",
    "    print('Model saved!')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print('Loading iris data set...')\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    print('Dataset loaded!')\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap runtime code\n",
    "We will now create runtime code to get predictions and wrap this into a Docker container so it can be launched inside seldon-core. The runtime code is defined in the file IrisClassifier.py and is show below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.externals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mIrisClassifier\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[36mself\u001b[39;49;00m.model = joblib.load(\u001b[33m'\u001b[39;49;00m\u001b[33mIrisClassifier.sav\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.class_names = [\u001b[33m\"\u001b[39;49;00m\u001b[33miris-setosa\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33miris-vericolor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33miris-virginica\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m];\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mpredict\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,X,features_names):\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.model.predict_proba(X)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize IrisClassifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap this model we will use S2I (Source to Image) which will take this code and wrap it with a REST server so it can be deployed inside seldon. The wrapping process needs some details on where the runtime code is and what type of endpoint to create: REST or gRPC. This is held in the .s2i folder in a file called *environment*. This file is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME=IrisClassifier\r\n",
      "API_TYPE=REST\r\n",
      "SERVICE_TYPE=MODEL\r\n",
      "PERSISTENCE=0\r\n"
     ]
    }
   ],
   "source": [
    "!cat .s2i/environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to wrap the model using s2i. We need to choose a Seldon builder image. Seldon provides builder images for python (2 and 3) and also R and Java. In this case we choose python 3. We also need to provide the name of the image we wish to build. Replace *my-repo* with the name of your Docker repository. We also provide a requirements.txt with the needed python packages. To get more details on wrapping python models for seldon-core see [here](https://github.com/SeldonIO/seldon-core/blob/master/docs/wrappers/python.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**change below to your Docker repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DOCKER_REPO=seldonio\n"
     ]
    }
   ],
   "source": [
    "%env DOCKER_REPO=seldonio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "---> Installing dependencies ...\n",
      "Collecting scikit-learn==0.19.0 (from -r requirements.txt (line 1))\n",
      "Downloading https://files.pythonhosted.org/packages/a4/b3/209652a5d60ce4a2a8a35ad893d7565bbb0f87ce043264ba5c9e7de304cd/scikit_learn-0.19.0-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
      "Collecting scipy==0.18.1 (from -r requirements.txt (line 2))\n",
      "Downloading https://files.pythonhosted.org/packages/74/c0/f0bf4eaef1b6aa7bdd1ae5597ce1d9e729417b3ca085c47d0f1c640d34f8/scipy-0.18.1-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
      "Installing collected packages: scikit-learn, scipy\n",
      "Successfully installed scikit-learn-0.19.0 scipy-0.18.1\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build . seldonio/seldon-core-s2i-python3 ${DOCKER_REPO}/sklearn-iris:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the image has been built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldonio/sklearn-iris                                          0.1                 c65c10203966        2 seconds ago       1.25GB\r\n",
      "seldonio/sklearn-iris                                          <none>              e3e2ac61aa79        5 hours ago         1.25GB\r\n",
      "seldonio/sklearn-iris                                          <none>              ed98829dd467        6 hours ago         1.25GB\r\n",
      "seldonio/sklearn-iris                                          <none>              8c83a438f912        7 hours ago         1.25GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker images | grep sklearn-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now push this image to your repo so we can use it inside your seldon-core cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/seldonio/sklearn-iris]\n",
      "\n",
      "\u001b[1B4e067887: Preparing \n",
      "\u001b[1Bcd490e05: Preparing \n",
      "\u001b[1Bed9127c2: Preparing \n",
      "\u001b[1Bc90ed723: Preparing \n",
      "\u001b[1B69d7992c: Preparing \n",
      "\u001b[1Be783060b: Preparing \n",
      "\u001b[1B4c18b186: Preparing \n",
      "\u001b[1B4e44553f: Preparing \n",
      "\u001b[1B50bdb983: Preparing \n",
      "\u001b[1B5c484bde: Preparing \n",
      "\u001b[1B34df1f1a: Preparing \n",
      "\u001b[1B8bf2f209: Preparing \n",
      "\u001b[1Bb36b7599: Preparing \n",
      "\u001b[1Bd5dcea45: Preparing \n",
      "\u001b[1Bd020c11b: Preparing \n",
      "\u001b[1B4afd042f: Preparing \n",
      "\u001b[17Be067887: Pushed   269.4MB/267.3MB14A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K0.1: digest: sha256:19d38e42c6bcd71bf91e9a7c38c93e3c2aa067ba0089be3b36c7d99202c43e1f size: 3899\n"
     ]
    }
   ],
   "source": [
    "!docker push ${DOCKER_REPO}/sklearn-iris:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model \n",
    "We will now deploy a runtime graph to serve our model on our seldon-core cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequistes\n",
    "\n",
    " * You have a running cluster installed via the Google Marketplace with all the defaults including:\n",
    "    * NodePort for the Seldon API OAuth Gateway. This gateway is used to connect your business apps to your running models via REST and gRPC.\n",
    "    * The cluster is running in the default namespace\n",
    " \n",
    " You will need to install some software for this demo:\n",
    " \n",
    " \n",
    " * Install the [requests library](http://docs.python-requests.org/en/master/) to allow you to make REST calls to the Seldon API gateway.\n",
    " * Install [python grpc tools](https://grpc.io/docs/quickstart/python.html) to allow you to make gRPC calls to the Seldon API gateway.\n",
    " * Install [graphviz](https://pypi.org/project/graphviz/) a package to display graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up REST and gRPC methods\n",
    "\n",
    "**Ensure you port forward the seldon api-server REST and GRPC ports**, do this in separate terminals:\n",
    "\n",
    "REST:\n",
    "```\n",
    "kubectl port-forward $(kubectl get pods -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].metadata.name}') 8002:8080\n",
    "```\n",
    "\n",
    "GRPC:\n",
    "```\n",
    "kubectl port-forward $(kubectl get pods -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].metadata.name}') 8003:5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from proto import prediction_pb2\n",
    "from proto import prediction_pb2_grpc\n",
    "import grpc\n",
    "try:\n",
    "    from commands import getoutput # python 2\n",
    "except ImportError:\n",
    "    from subprocess import getoutput # python 3\n",
    "\n",
    "API_HTTP=\"localhost:8002\"\n",
    "API_GRPC=\"localhost:8003\"\n",
    "\n",
    "def get_token():\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    response = requests.post(\n",
    "                \"http://\"+API_HTTP+\"/oauth/token\",\n",
    "                auth=HTTPBasicAuth('oauth-key', 'oauth-secret'),\n",
    "                data=payload)\n",
    "    print(response.text)\n",
    "    token =  response.json()[\"access_token\"]\n",
    "    return token\n",
    "\n",
    "def rest_request():\n",
    "    token = get_token()\n",
    "    headers = {'Authorization': 'Bearer '+token}\n",
    "    payload = {\"data\":{\"names\":[\"sepallengthcm\",\"sepalwidthcm\",\"petallengthcm\",\"petalwidthcm\"],\"tensor\":{\"shape\":[1,4],\"values\":[5.1,3.5,1.4,0.2]}}}\n",
    "    response = requests.post(\n",
    "                \"http://\"+API_HTTP+\"/api/v0.1/predictions\",\n",
    "                headers=headers,\n",
    "                json=payload)\n",
    "    print(response.text)\n",
    "    \n",
    "def grpc_request():\n",
    "    token = get_token()\n",
    "    datadef = prediction_pb2.DefaultData(\n",
    "            names = [\"sepallengthcm\",\"sepalwidthcm\",\"petallengthcm\",\"petalwidthcm\"],\n",
    "            tensor = prediction_pb2.Tensor(\n",
    "                shape = [1,4],\n",
    "                values = [5,1,3.5,1.4,0.2]\n",
    "                )\n",
    "            )\n",
    "    request = prediction_pb2.SeldonMessage(data = datadef)\n",
    "    channel = grpc.insecure_channel(API_GRPC)\n",
    "    stub = prediction_pb2_grpc.SeldonStub(channel)\n",
    "    metadata = [('oauth_token', token)]\n",
    "    response = stub.Predict(request=request,metadata=metadata)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to describe a runtime graph for our iris model so we can deploy it using seldon-core. This is shown below. We will update ${DOCKER_REPO} with our given docker repository we set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \u001b[34;01m\"apiVersion\"\u001b[39;49;00m: \u001b[33m\"machinelearning.seldon.io/v1alpha2\"\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"kind\"\u001b[39;49;00m: \u001b[33m\"SeldonDeployment\"\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"metadata\"\u001b[39;49;00m: {\r\n",
      "        \u001b[34;01m\"labels\"\u001b[39;49;00m: {\r\n",
      "            \u001b[34;01m\"app\"\u001b[39;49;00m: \u001b[33m\"seldon\"\u001b[39;49;00m\r\n",
      "        },\r\n",
      "        \u001b[34;01m\"name\"\u001b[39;49;00m: \u001b[33m\"sklearn-iris-example\"\u001b[39;49;00m\r\n",
      "    },\r\n",
      "    \u001b[34;01m\"spec\"\u001b[39;49;00m: {\r\n",
      "        \u001b[34;01m\"name\"\u001b[39;49;00m: \u001b[33m\"sklearn-iris-deployment\"\u001b[39;49;00m,\r\n",
      "        \u001b[34;01m\"oauth_key\"\u001b[39;49;00m: \u001b[33m\"oauth-key\"\u001b[39;49;00m,\r\n",
      "        \u001b[34;01m\"oauth_secret\"\u001b[39;49;00m: \u001b[33m\"oauth-secret\"\u001b[39;49;00m,\r\n",
      "        \u001b[34;01m\"predictors\"\u001b[39;49;00m: [\r\n",
      "            {\r\n",
      "                \u001b[34;01m\"componentSpecs\"\u001b[39;49;00m: [{\r\n",
      "                    \u001b[34;01m\"spec\"\u001b[39;49;00m: {\r\n",
      "                        \u001b[34;01m\"containers\"\u001b[39;49;00m: [\r\n",
      "                            {\r\n",
      "                                \u001b[34;01m\"image\"\u001b[39;49;00m: \u001b[33m\"${DOCKER_REPO}/sklearn-iris:0.1\"\u001b[39;49;00m,\r\n",
      "                                \u001b[34;01m\"imagePullPolicy\"\u001b[39;49;00m: \u001b[33m\"IfNotPresent\"\u001b[39;49;00m,\r\n",
      "                                \u001b[34;01m\"name\"\u001b[39;49;00m: \u001b[33m\"sklearn-iris-classifier\"\u001b[39;49;00m,\r\n",
      "                                \u001b[34;01m\"resources\"\u001b[39;49;00m: {\r\n",
      "                                    \u001b[34;01m\"requests\"\u001b[39;49;00m: {\r\n",
      "                                        \u001b[34;01m\"memory\"\u001b[39;49;00m: \u001b[33m\"1Mi\"\u001b[39;49;00m\r\n",
      "                                    }\r\n",
      "                                }\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \u001b[34;01m\"terminationGracePeriodSeconds\"\u001b[39;49;00m: \u001b[34m20\u001b[39;49;00m\r\n",
      "                    }\r\n",
      "                }],\r\n",
      "                \u001b[34;01m\"graph\"\u001b[39;49;00m: {\r\n",
      "                    \u001b[34;01m\"children\"\u001b[39;49;00m: [],\r\n",
      "                    \u001b[34;01m\"name\"\u001b[39;49;00m: \u001b[33m\"sklearn-iris-classifier\"\u001b[39;49;00m,\r\n",
      "                    \u001b[34;01m\"endpoint\"\u001b[39;49;00m: {\r\n",
      "                        \u001b[34;01m\"type\"\u001b[39;49;00m : \u001b[33m\"REST\"\u001b[39;49;00m\r\n",
      "                    },\r\n",
      "                    \u001b[34;01m\"type\"\u001b[39;49;00m: \u001b[33m\"MODEL\"\u001b[39;49;00m\r\n",
      "                },\r\n",
      "                \u001b[34;01m\"name\"\u001b[39;49;00m: \u001b[33m\"classifier\"\u001b[39;49;00m,\r\n",
      "                \u001b[34;01m\"replicas\"\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m,\r\n",
      "                \u001b[34;01m\"annotations\"\u001b[39;49;00m: {\r\n",
      "                \u001b[34;01m\"predictor_version\"\u001b[39;49;00m : \u001b[33m\"0.1\"\u001b[39;49;00m\r\n",
      "                }\r\n",
      "            }\r\n",
      "        ]\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize TMPL_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update our deployment.json template with the name of our Docker Repo and apply this on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment \"sklearn-iris-example\" created\r\n"
     ]
    }
   ],
   "source": [
    "!cat TMPL_deployment.json | envsubst | kubectl apply -f - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the status of the SeldonDeployment. **When ready the replicasAvailable should be 1 for all components**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map[predictorStatus:[map[name:sklearn-iris-deployment-classifier-svc-orch replicas:1 replicasAvailable:1] map[name:sklearn-iris-deployment-classifier-sklearn-iris-classifier-0 replicas:1 replicasAvailable:1]]]"
     ]
    }
   ],
   "source": [
    "!kubectl get seldondeployments sklearn-iris-example -o jsonpath='{.status}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REST Request\n",
    "We will get an OAuth token using the key and secret we specified in the graph above and then call the REST endpoint of the API gateway with some random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"access_token\":\"93f81a9e-4658-4e34-8f0a-cf232c125a20\",\"token_type\":\"bearer\",\"expires_in\":42935,\"scope\":\"read write\"}\n",
      "{\n",
      "  \"meta\": {\n",
      "    \"puid\": \"g15i4319ihek4hf89tphs5dspu\",\n",
      "    \"tags\": {\n",
      "    },\n",
      "    \"routing\": {\n",
      "    }\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"names\": [\"iris-setosa\", \"iris-vericolor\", \"iris-virginica\"],\n",
      "    \"tensor\": {\n",
      "      \"shape\": [1, 3],\n",
      "      \"values\": [0.8796816489561845, 0.12030753790658998, 1.0813137225507727E-5]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rest_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tear Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment \"sklearn-iris-example\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!cat TMPL_deployment.json | envsubst | kubectl delete -f -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "There is extensive documentation on using seldon-core at https://github.com/SeldonIO/seldon-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
